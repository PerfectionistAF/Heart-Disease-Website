{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ab9295",
   "metadata": {},
   "source": [
    "# For optimization, less intermediate files saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48068528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "#import PIL.Image\n",
    "import matplotlib \n",
    "# import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import shutil\n",
    "import posixpath\n",
    "import sys \n",
    "import glob\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import math\n",
    "#from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03265dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_ii_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_ii_images.keras\n",
      "resnet50_v6_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_v6_images.keras\n",
      "resnet50_vz_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_vz_images.keras\n",
      "file_ii: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/ii/28.csv.png\n",
      "file_v6: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/v6/28.csv.png\n",
      "file_vz: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/vz/28.csv.png\n"
     ]
    }
   ],
   "source": [
    "# current_dir = os.path.dirname(os.path.abspath(__file__))  # if using .py\n",
    "current_dir = os.getcwd()  # if using ipynb\n",
    "\n",
    "resnet50_ii_filename = os.path.join(current_dir, \"resnet50_ii_images.keras\")\n",
    "resnet50_v6_filename = os.path.join(current_dir, \"resnet50_v6_images.keras\")\n",
    "resnet50_vz_filename = os.path.join(current_dir, \"resnet50_vz_images.keras\")\n",
    "\n",
    "file_ii = os.path.join(current_dir, \"ecg_image/ii/28.csv.png\")\n",
    "file_v6 = os.path.join(current_dir, \"ecg_image/v6/28.csv.png\")\n",
    "file_vz = os.path.join(current_dir, \"ecg_image/vz/28.csv.png\")\n",
    "\n",
    "print(f\"resnet50_ii_filename: {resnet50_ii_filename}\")\n",
    "print(f\"resnet50_v6_filename: {resnet50_v6_filename}\")\n",
    "print(f\"resnet50_vz_filename: {resnet50_vz_filename}\")\n",
    "\n",
    "print(f\"file_ii: {file_ii}\")\n",
    "print(f\"file_v6: {file_v6}\")\n",
    "print(f\"file_vz: {file_vz}\")\n",
    "\n",
    "# # Load the three models\n",
    "# model_ii = load_model(resnet50_ii_filename)\n",
    "# model_v6 = load_model(resnet50_v6_filename)\n",
    "# model_vz = load_model(resnet50_vz_filename)\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    img = image.load_img(image_path, target_size=(224, 224, 3))\n",
    "    x = image.img_to_array(img, data_format='channels_last')\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return preds\n",
    "\n",
    "def interpret_combined_prediction(preds_ii, preds_v6, preds_vz):\n",
    "    # Interpret each lead's prediction\n",
    "    healthy_ii = preds_ii[0][0] > preds_ii[0][1]\n",
    "    healthy_v6 = preds_v6[0][0] > preds_v6[0][1]\n",
    "    healthy_vz = preds_vz[0][0] > preds_vz[0][1]\n",
    "    \n",
    "    # Determine if the patient is sick based on at least 2 leads indicating sickness\n",
    "    sick_count = 0\n",
    "    if not healthy_ii:\n",
    "        sick_count += 1\n",
    "    if not healthy_v6:\n",
    "        sick_count += 1\n",
    "    if not healthy_vz:\n",
    "        sick_count += 1\n",
    "    \n",
    "    if sick_count >= 2:\n",
    "        return \"The patient is more likely to have Myocardial Infarction (MI).\"\n",
    "    else:\n",
    "        return \"The patient is more likely to be healthy.\"\n",
    "\n",
    "def preprocess_and_extract_images(dat_files, destination_path, channel):\n",
    "    for file in dat_files:\n",
    "        record = wfdb.rdrecord(os.path.splitext(file)[0], sampto=1000)\n",
    "        df = pd.DataFrame(record.p_signal, columns=record.sig_name)\n",
    "        graph = np.array(df[channel])\n",
    "        plt.plot(graph, label='Channel: ' + channel)\n",
    "        plt.savefig(os.path.join(destination_path, os.path.basename(file) + '.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Define the relative path to the directory containing ECG .dat files\n",
    "relative_ptb_path = os.path.join(current_dir, 'ecg_dat', '*.dat')\n",
    "ptb_files = glob.glob(relative_ptb_path)\n",
    "\n",
    "# Ensure the destination directories exist\n",
    "os.makedirs(os.path.join(current_dir, 'ecg_image/ii'), exist_ok=True)\n",
    "os.makedirs(os.path.join(current_dir, 'ecg_image/v6'), exist_ok=True)\n",
    "os.makedirs(os.path.join(current_dir, 'ecg_image/vz'), exist_ok=True)\n",
    "\n",
    "# Preprocess and extract images directly from .dat files to images\n",
    "preprocess_and_extract_images(ptb_files, os.path.join(current_dir, 'ecg_image/ii'), 'ii')\n",
    "preprocess_and_extract_images(ptb_files, os.path.join(current_dir, 'ecg_image/v6'), 'v6')\n",
    "preprocess_and_extract_images(ptb_files, os.path.join(current_dir, 'ecg_image/vz'), 'vz')\n",
    "\n",
    "# Example usage\n",
    "# file_ii = \"path_to_your_image_file_ii.jpg\"  # Replace with the actual path to your image file for model ii\n",
    "# file_v6 = \"path_to_your_image_file_v6.jpg\"  # Replace with the actual path to your image file for model v6\n",
    "# file_vz = \"path_to_your_image_file_vz.jpg\"  # Replace with the actual path to your image file for model vz\n",
    "\n",
    "# # Predict 1/3\n",
    "# preds_ii = predict_image(file_ii, model_ii)\n",
    "# print(\"ii: \", preds_ii)\n",
    "\n",
    "# # Predict 2/3\n",
    "# preds_v6 = predict_image(file_v6, model_v6)\n",
    "# print(\"v6: \", preds_v6)\n",
    "\n",
    "# # Predict 3/3\n",
    "# preds_vz = predict_image(file_vz, model_vz)\n",
    "# print(\"vz: \", preds_vz)\n",
    "\n",
    "# # Combine predictions and interpret result\n",
    "# combined_status = interpret_combined_prediction(preds_ii, preds_v6, preds_vz)\n",
    "# print(combined_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5818a",
   "metadata": {},
   "source": [
    " What if I just want to preprocess a single dat file -> 3 images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be47c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_ii_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_ii_images.keras\n",
      "resnet50_v6_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_v6_images.keras\n",
      "resnet50_vz_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_vz_images.keras\n"
     ]
    }
   ],
   "source": [
    "# current_dir = os.path.dirname(os.path.abspath(__file__))  # if using .py\n",
    "current_dir = os.getcwd()  # if using ipynb\n",
    "\n",
    "resnet50_ii_filename = os.path.join(current_dir, \"resnet50_ii_images.keras\")\n",
    "resnet50_v6_filename = os.path.join(current_dir, \"resnet50_v6_images.keras\")\n",
    "resnet50_vz_filename = os.path.join(current_dir, \"resnet50_vz_images.keras\")\n",
    "\n",
    "print(f\"resnet50_ii_filename: {resnet50_ii_filename}\")\n",
    "print(f\"resnet50_v6_filename: {resnet50_v6_filename}\")\n",
    "print(f\"resnet50_vz_filename: {resnet50_vz_filename}\")\n",
    "\n",
    "# # Load the three models\n",
    "# model_ii = load_model(resnet50_ii_filename)\n",
    "# model_v6 = load_model(resnet50_v6_filename)\n",
    "# model_vz = load_model(resnet50_vz_filename)\n",
    "\n",
    "# def predict_image(image_path, model):\n",
    "#     img = image.load_img(image_path, target_size=(224, 224, 3))\n",
    "#     x = image.img_to_array(img, data_format='channels_last')\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     x = preprocess_input(x)\n",
    "#     preds = model.predict(x)\n",
    "#     return preds\n",
    "\n",
    "# def interpret_combined_prediction(preds_ii, preds_v6, preds_vz):\n",
    "#     # Interpret each lead's prediction\n",
    "#     healthy_ii = preds_ii[0][0] > preds_ii[0][1]\n",
    "#     healthy_v6 = preds_v6[0][0] > preds_v6[0][1]\n",
    "#     healthy_vz = preds_vz[0][0] > preds_vz[0][1]\n",
    "    \n",
    "#     # Determine if the patient is sick based on at least 2 leads indicating sickness\n",
    "#     sick_count = 0\n",
    "#     if not healthy_ii:\n",
    "#         sick_count += 1\n",
    "#     if not healthy_v6:\n",
    "#         sick_count += 1\n",
    "#     if not healthy_vz:\n",
    "#         sick_count += 1\n",
    "    \n",
    "#     if sick_count >= 2:\n",
    "#         return \"The patient is more likely to have Myocardial Infarction (MI).\"\n",
    "#     else:\n",
    "#         return \"The patient is more likely to be healthy.\"\n",
    "\n",
    "def preprocess_single_file(dat_file, destination_path, channels):\n",
    "    record = wfdb.rdrecord(os.path.splitext(dat_file)[0], sampto=1000)\n",
    "    df = pd.DataFrame(record.p_signal, columns=record.sig_name)\n",
    "\n",
    "    for channel in channels:\n",
    "        if channel in df.columns:\n",
    "            graph = np.array(df[channel])\n",
    "            plt.plot(graph, label='Channel: ' + channel)\n",
    "\n",
    "            # Ensure the destination directory exists\n",
    "            os.makedirs(destination_path, exist_ok=True)\n",
    "            plt.savefig(os.path.join(destination_path, os.path.basename(dat_file) + f'_{channel}.png'))\n",
    "            plt.close()\n",
    "\n",
    "# Example usage: preprocess a single .dat file\n",
    "single_dat_file = os.path.join(current_dir, 'ecg_dat', 's0028lre.dat')\n",
    "\n",
    "# Preprocess and extract images for the single .dat file\n",
    "preprocess_single_file(single_dat_file, os.path.join(current_dir, 'ecg_image/ii'), ['ii'])\n",
    "preprocess_single_file(single_dat_file, os.path.join(current_dir, 'ecg_image/v6'), ['v6'])\n",
    "preprocess_single_file(single_dat_file, os.path.join(current_dir, 'ecg_image/vz'), ['vz'])\n",
    "\n",
    "# # File paths for predictions\n",
    "# file_ii = os.path.join(current_dir, 'ecg_image/ii', 'example.dat_ii.png')\n",
    "# file_v6 = os.path.join(current_dir, 'ecg_image/v6', 'example.dat_v6.png')\n",
    "# file_vz = os.path.join(current_dir, 'ecg_image/vz', 'example.dat_vz.png')\n",
    "\n",
    "# # Predict 1/3\n",
    "# preds_ii = predict_image(file_ii, model_ii)\n",
    "# print(\"ii: \", preds_ii)\n",
    "\n",
    "# # Predict 2/3\n",
    "# preds_v6 = predict_image(file_v6, model_v6)\n",
    "# print(\"v6: \", preds_v6)\n",
    "\n",
    "# # Predict 3/3\n",
    "# preds_vz = predict_image(file_vz, model_vz)\n",
    "# print(\"vz: \", preds_vz)\n",
    "\n",
    "# # Combine predictions and interpret result\n",
    "# combined_status = interpret_combined_prediction(preds_ii, preds_v6, preds_vz)\n",
    "# print(combined_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976f31f",
   "metadata": {},
   "source": [
    "# For py file imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes on directories:\n",
    "# All in context of Preprocessing\n",
    "# input dirs: ecg_dat and ecg_csv\n",
    "# intermediate output dirs: ptb_ecg_db_csv and ptb_ecg_db_txt\n",
    "# output dirs: ecg_image and its subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94358c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERY IMPORTANT NOTE please ignore these outdated imports which mess up everything!\n",
    "# import os\n",
    "# # os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"jax\" or \"torch\"\n",
    "# # from keras.applications.vgg16 import VGG16\n",
    "# # from keras.applications.vgg16 import decode_predictions\n",
    "# # from tensorflow.keras.preprocessing import image\n",
    "# # from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# # from keras import backend\n",
    "\n",
    "# from tkinter import Image\n",
    "# import glob\n",
    "# import wfdb\n",
    "# import pandas as pd\n",
    "# # from tensorflow import keras\n",
    "# from tensorflow.keras.models import load_model\n",
    "# # import tensorflow as tf\n",
    "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d69dd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_ii_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_ii_images.keras\n",
      "resnet50_v6_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_v6_images.keras\n",
      "resnet50_vz_filename: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\resnet50_vz_images.keras\n",
      "file_ii: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/ii/28.csv.png\n",
      "file_v6: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/v6/28.csv.png\n",
      "file_vz: d:\\MyData\\Salma\\uni\\years\\Senior-2\\Spring 2024\\CSE492 Graduation Project (2)\\django\\integration demo 2\\Heart-Disease-Website\\integration_demo\\backend\\core\\users\\machine learning models\\ecg_image/vz/28.csv.png\n"
     ]
    }
   ],
   "source": [
    "# current_dir = os.path.dirname(os.path.abspath(__file__)) # if using .py\n",
    "current_dir = os.getcwd() # if using ipynb\n",
    "\n",
    "resnet50_ii_filename = os.path.join(current_dir, \"resnet50_ii_images.keras\")\n",
    "resnet50_v6_filename = os.path.join(current_dir, \"resnet50_v6_images.keras\")\n",
    "resnet50_vz_filename = os.path.join(current_dir, \"resnet50_vz_images.keras\")\n",
    "\n",
    "file_ii = os.path.join(current_dir, \"ecg_image/ii/28.csv.png\")\n",
    "file_v6 = os.path.join(current_dir, \"ecg_image/v6/28.csv.png\")\n",
    "file_vz = os.path.join(current_dir, \"ecg_image/vz/28.csv.png\")\n",
    "\n",
    "print(f\"resnet50_ii_filename: {resnet50_ii_filename}\")\n",
    "print(f\"resnet50_v6_filename: {resnet50_v6_filename}\")\n",
    "print(f\"resnet50_vz_filename: {resnet50_vz_filename}\")\n",
    "\n",
    "print(f\"file_ii: {file_ii}\")\n",
    "print(f\"file_v6: {file_v6}\")\n",
    "print(f\"file_vz: {file_vz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5377bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: from signal records to csv\n",
    "\n",
    "#PTB DATASET\n",
    "#Convert all to csv then to txt\n",
    "def preprocess_dat_to_csv():\n",
    "\n",
    "    # Define the relative path to the directory containing ECG .dat files\n",
    "    relative_ptb_path = os.path.join(current_dir, 'ecg_dat', '*.dat')\n",
    "\n",
    "    # Find all .dat files matching the pattern in the relative directory\n",
    "    ptb_files = glob.glob(relative_ptb_path)\n",
    "\n",
    "    # Debugging: print the path being searched and the files found\n",
    "    print(f\"Searching for files in: {os.path.dirname(relative_ptb_path)}\")\n",
    "    print(f\"Number of files found: {len(ptb_files)}\")\n",
    "\n",
    "    # Print the contents of the directory\n",
    "    directory_path = os.path.dirname(relative_ptb_path)\n",
    "    try:\n",
    "        print(f\"Contents of directory {directory_path}:\")\n",
    "        print(os.listdir(directory_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The directory {directory_path} does not exist. Please check the path.\")\n",
    "\n",
    "    # Proceed if files are found\n",
    "    if ptb_files:\n",
    "        # List to store WFDB records\n",
    "        ptb_record_list = []\n",
    "\n",
    "        # Read each file and store the record\n",
    "        for file in ptb_files:\n",
    "            name = os.path.splitext(file)[0]\n",
    "            ptb_record_list.append(wfdb.rdrecord(name, sampto=1000))\n",
    "\n",
    "        # List to store DataFrames\n",
    "        ptb_df_list = []\n",
    "\n",
    "        # Convert records to DataFrames and save as CSV files\n",
    "        for i, record in enumerate(ptb_record_list):\n",
    "            df = pd.DataFrame(record.p_signal, columns=record.sig_name)\n",
    "            ptb_df_list.append(df)\n",
    "\n",
    "            # Define the relative paths for the directories\n",
    "            csv_directory = os.path.join(current_dir, 'ptb_ecg_db_csv')\n",
    "            txt_directory = os.path.join(current_dir, 'ptb_ecg_db_txt')\n",
    "\n",
    "            # Create directories if they don't exist\n",
    "            os.makedirs(csv_directory, exist_ok=True)\n",
    "            os.makedirs(txt_directory, exist_ok=True)\n",
    "\n",
    "            # Save CSV file\n",
    "            csv_name = os.path.join(csv_directory, f'{i}.csv')\n",
    "            df.to_csv(csv_name, index=False)\n",
    "\n",
    "        # Convert CSV files to TXT files\n",
    "        for i in range(len(ptb_record_list)):\n",
    "            csv_name = os.path.join(csv_directory, f'{i}.csv')\n",
    "            txt_name = os.path.join(txt_directory, f'{i}.txt')\n",
    "            with open(csv_name, 'r') as f_in, open(txt_name, 'w') as f_out:\n",
    "                content = f_in.read()\n",
    "                f_out.write(content)\n",
    "\n",
    "        print(\"Processing complete.\")\n",
    "    else:\n",
    "        print(\"No files found. Please check the directory and file pattern.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3e97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: csv to images\n",
    "\n",
    "##Resize images to default pretrained tensor size: 224, 224, 3\n",
    "def new_images(path):\n",
    "    for image in os.listdir(path):\n",
    "        print(image)\n",
    "        name = os.path.basename(image)\n",
    "        image = Image.open(path +'/' + image)\n",
    "        resized_image = image.resize((224, 224))\n",
    "        resized_image.save(path +'/' + name)\n",
    "\n",
    "##extract images of separate channels from csv without transformation--data is already clean\n",
    "def extract_images(source_path, destination_path, channel):\n",
    "    for file in os.listdir(source_path):\n",
    "        #open csv from the source_path\n",
    "        df = pd.read_csv(source_path+'/'+file)\n",
    "        #that channel values are converted to arrays to ease graphing\n",
    "        graph = np.array(df[channel])\n",
    "        #plot the channel points\n",
    "        image = plt.plot(graph, label='Channel:'+ channel)\n",
    "        #save the image in the destination\n",
    "        plt.savefig(destination_path+'/'+file+'.png')\n",
    "        #graph is reset and plot is closed to avoid overlap\n",
    "        plt.close()\n",
    "        graph = 0\n",
    "        image = 0\n",
    "        \n",
    "    return \n",
    "\n",
    "##same as extract_images except with 2 channels at the same time to test reciprocity\n",
    "def multi_extract_images(source_path, destination_path, channel1, channel2):\n",
    "    for file in os.listdir(source_path):\n",
    "        #open csv from the source_path\n",
    "        df = pd.read_csv(source_path+'/'+file)\n",
    "        #that channel values are converted to arrays to ease graphing\n",
    "        graph1 = np.array(df[channel1])\n",
    "        graph2 = np.array(df[channel2])\n",
    "        #plot the channel points\n",
    "        image = plt.plot(graph1, label='Channel:'+ channel1)\n",
    "        image = plt.plot(graph2, label='Channel:'+ channel2)\n",
    "        #save the image in the destination\n",
    "        plt.savefig(destination_path+'/'+file+'.png')\n",
    "        #graph is reset and plot is closed to avoid overlap\n",
    "        plt.close()\n",
    "        graph = 0\n",
    "        image = 0\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec721c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predict\n",
    "\n",
    "def predict_image(image_path, model):   ##overload function\n",
    "    img = image.load_img(image_path, target_size=(224, 224, 3))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return preds\n",
    "\n",
    "def disease_predict(array):\n",
    "    label = 0\n",
    "    for i in range(0,2):\n",
    "        if array[0][0] < array[0][1] :\n",
    "            label = 1\n",
    "\n",
    "    return label\n",
    "\n",
    "# def generate_label(predict_array):\n",
    "#     label = 0\n",
    "#     count = 0\n",
    "#     for i in range(predict_array.shape[1]):\n",
    "#         if predict_array[0][i] == 1 :\n",
    "#             count = count + 1\n",
    "#     if count >= (2 * 3) * predict_array.shape[1]:  \n",
    "#         label = 1\n",
    "#     return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc74b9",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "# Preprocessing\n",
    "# dat to csv\n",
    "preprocess_dat_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv to img\n",
    "# for ecg_csv files\n",
    "extract_images(os.path.join(current_dir, 'ecg_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/ii'),\n",
    "               'ii')\n",
    "extract_images(os.path.join(current_dir, 'ecg_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/v6'),\n",
    "               'v6')\n",
    "extract_images(os.path.join(current_dir, 'ecg_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/vz'),\n",
    "               'vz')\n",
    "# for ecg_dat -> ptb_ecg_db_csv files\n",
    "extract_images(os.path.join(current_dir, 'ptb_ecg_db_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/ii'),\n",
    "               'ii')\n",
    "extract_images(os.path.join(current_dir, 'ptb_ecg_db_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/v6'),\n",
    "               'v6')\n",
    "extract_images(os.path.join(current_dir, 'ptb_ecg_db_csv'),\n",
    "               os.path.join(current_dir, 'ecg_image/vz'),\n",
    "               'vz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b61e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "#import PIL.Image\n",
    "import matplotlib \n",
    "# import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import posixpath\n",
    "import sys \n",
    "import glob\n",
    "#import wfdb\n",
    "import pandas as pd\n",
    "import math\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3b669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three models\n",
    "from tensorflow.keras.models import load_model\n",
    "model_ii = load_model(resnet50_ii_filename)\n",
    "model_v6 = load_model(resnet50_v6_filename)\n",
    "model_vz = load_model(resnet50_vz_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3df68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32s/step\n",
      "ii:  [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Predict 1/3\n",
    "preds_ii = predict_image(file_ii, model_ii)\n",
    "print(\"ii: \", preds_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbad2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step\n",
      "v6:  [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Predict 2/3\n",
    "preds_v6 = predict_image(file_v6, model_v6)\n",
    "print(\"v6: \", preds_v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0beb1730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 97s/step\n",
      "vz:  [[4.0830894e-28 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Predict 3/3\n",
    "preds_vz = predict_image(file_vz, model_vz)\n",
    "print(\"vz: \", preds_vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33697620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient is more likely to have Myocardial Infarction (MI).\n"
     ]
    }
   ],
   "source": [
    "def interpret_combined_prediction(preds_ii, preds_v6, preds_vz):\n",
    "    # Interpret each lead's prediction\n",
    "    healthy_ii = preds_ii[0][0] > preds_ii[0][1]\n",
    "    healthy_v6 = preds_v6[0][0] > preds_v6[0][1]\n",
    "    healthy_vz = preds_vz[0][0] > preds_vz[0][1]\n",
    "    \n",
    "    # Determine if the patient is sick based on at least 2 leads indicating sickness\n",
    "    sick_count = 0\n",
    "    if not healthy_ii:\n",
    "        sick_count += 1\n",
    "    if not healthy_v6:\n",
    "        sick_count += 1\n",
    "    if not healthy_vz:\n",
    "        sick_count += 1\n",
    "    \n",
    "    if sick_count >= 2:\n",
    "        return \"The patient is more likely to have Myocardial Infarction (MI).\"\n",
    "    else:\n",
    "        return \"The patient is more likely to be healthy.\"                                   \n",
    "    \n",
    "# Combine predictions and interpret result\n",
    "combined_status = interpret_combined_prediction(preds_ii, preds_v6, preds_vz)\n",
    "print(combined_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ebcd7",
   "metadata": {},
   "source": [
    "## Fixing predict AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow is built with CUDA\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# List available GPUs\n",
    "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff92dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "img_data = np.random.random(size=(100, 100, 3))\n",
    "img = tf.keras.utils.array_to_img(img_data)\n",
    "array = tf.keras.utils.image.img_to_array(img)\n",
    "\n",
    "\n",
    "# x = tf.keras.utils.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "img_data = np.random.random(size=(100, 100, 3))\n",
    "img = keras.utils.array_to_img(img_data)\n",
    "array = keras.utils.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of converting an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "# load the image\n",
    "img = load_img(file_ii, target_size=(224, 224, 3))\n",
    "print(type(img))\n",
    "# convert to numpy array\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.dtype)\n",
    "print(img_array.shape)\n",
    "# convert back to image\n",
    "img_pil = array_to_img(img_array)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d57cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(file_ii, target_size=(224, 224, 3))\n",
    "x = img\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model_ii.predict(x)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3477104",
   "metadata": {},
   "source": [
    "# Sohaila's imp notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cebf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "#import PIL.Image\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "import posixpath\n",
    "import sys \n",
    "import glob\n",
    "#import wfdb\n",
    "import pandas as pd\n",
    "import math\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1131bc07-ad54-4050-95dd-41e1d1d1b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0bac94-558d-4cf2-8484-ddbb356873e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model):   ##overload function\n",
    "    img = image.load_img(image_path, target_size=(224, 224, 3))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccf015-f1c2-4af8-8e33-26faa3656e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_predict(array):\n",
    "    label = 0\n",
    "    for i in range(0,2):\n",
    "        if array[0][0] < array[0][1] :\n",
    "            label = 1\n",
    "\n",
    "    return label\n",
    "\n",
    "def generate_label(predict_array):\n",
    "    label = 0\n",
    "    count = 0\n",
    "    for i in range(predict_array.shape[1]):\n",
    "        if predict_array[0][i] == 1 :\n",
    "            count = count + 1\n",
    "    if count >= (2 * 3) * predict_array.shape[1]:  \n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd21810-274c-4ab5-ab35-1d06cb5a1083",
   "metadata": {},
   "source": [
    "## _FEATURE IMAGE BASED MODEL, 5 CHANNELS UNDER HERMITE TRANSFORM, 2 CLASSES_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f375f84-e907-47a9-a37e-2b17a77000d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model\n",
    "model = keras.saving.load_model('./models/resnet50_multi_images.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9774c3-b4ee-44a5-9042-4347faa1dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('sample_ecg_1089.png')  ##new model---image based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c89a7-b0b5-426a-a5a7-2a55e31635ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('sample_ecg_0.png')   ##new model---image based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860a55b-fee5-4c9d-9617-8aa8b15db6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('./ptb_ecg_filtered/train_multi/Healthy control/948_multiple_ Healthy control.png')##new model---image based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ffa0b-0950-4a7c-bc53-d0ad831324bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('12_sick_single.png')##new model---image based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcefa6c-a209-4a5c-9aa6-169accad2bee",
   "metadata": {},
   "source": [
    "## _CHANNEL IMAGE BASED MODEL, 3 SEPARATE CHANNELS WITHOUT BASELINE, 2 CLASSES_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772a203-3461-4c39-93e6-baab1a39faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model\n",
    "model_ii = keras.saving.load_model('./models/resnet50_ii_images.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677d158-0430-4ef1-a6f8-3f28e2f7ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('./ptb_resnet_rerun/second_arch/ii/Myocardial Infarction/1.csv.png', model_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0969e-2440-4118-a8b3-902cb0223c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model\n",
    "model_v6 = keras.saving.load_model('./models/resnet50_v6_images.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cc773-87db-4a7e-aef0-ef4fe3624edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('./ptb_resnet_rerun/second_arch/v6/Myocardial Infarction/1.csv.png', model_v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f371715-ca49-4a7c-b2a3-eb4356dea0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model\n",
    "model_vz = keras.saving.load_model('./models/resnet50_vz_images.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb56b0-f5d4-4b8e-bd35-9b086887a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('./ptb_resnet_rerun/second_arch/vz/Healthy control/948.csv.png', model_vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e9477-f4c7-44a5-8458-6b4326378c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_label = disease_predict(predict_image('./ptb_resnet_rerun/second_arch/vz/Myocardial Infarction/1.csv.png', model_vz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0818764b-d028-460e-830f-6d25954d5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70b74b-b154-4d37-8305-cf93c5cb2af1",
   "metadata": {},
   "source": [
    "## _DELETED MODEL: FEATURE IMAGE BASED MODEL, 5 CHANNELS UNDER HERMITE TRANSFORM, 15 CLASSES_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc708fb-fa3f-4c06-901b-be3c89c9e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_class_prob(predictions):\n",
    "    _max = max(predictions[0])\n",
    "    solution = 0\n",
    "    for i in range(1, len(predictions[0])):\n",
    "        if predictions[0][i] == _max:\n",
    "            solution = i\n",
    "        continue\n",
    "            \n",
    "    return _max, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324bc8fb-5b5b-4849-8d9c-f9c5f4c66c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##old model\n",
    "img_path = './ptb_ecg_filtered/train_multi/Myocardial Infarction/16_multiple_ Myocardial infarction.png'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = loaded_model.predict(x, batch_size=32)\n",
    "print('Predicted:', preds)\n",
    "_max, soln = max_class_prob(preds)\n",
    "print('Max probability is at class number:', soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a39f2-9418-40ac-a969-8cf9347b9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##old model\n",
    "img_path = './ptb_ecg_filtered/train_multi/Healthy control/949_multiple_ Healthy control.png'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = loaded_model.predict(x, batch_size=32)\n",
    "print('Predicted:', preds)\n",
    "_max, soln = max_class_prob(preds)\n",
    "print('Max probability is at class number:', soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1faa3-85b7-4f0f-8d20-f8d19b848cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##old model\n",
    "img_path = './ptb_ecg_filtered/train_multi/Bundle branch block/1164_multiple_ Bundle branch block.png'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = loaded_model.predict(x, batch_size=32)\n",
    "print('Predicted:', preds)\n",
    "_max, soln = max_class_prob(preds)\n",
    "print('Max probability is at class number:', soln)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
